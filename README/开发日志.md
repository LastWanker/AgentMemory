【维护规则】本日志仅允许“追加补充”，禁止删除或改写既有内容。


# 开发日志（项目现状快照）
更新时间：2026-02-15

## 1. 项目定位与当前阶段
- 项目名称：Memory Indexer（记忆唤醒索引器）。
- 当前主目标：把输入文本转成“可检索指令”，通过粗召回 + 精排 + 路由输出 Top-k 记忆。
- 阶段判断：
  - MVP 检索闭环已成型（可建库、可检索、可评估、可演示）。
  - 软/半硬/硬路由接口已落地，可观测指标已接入。
  - 自监督训练仍是“骨架接口 + 小规模实验脚本”阶段，未形成稳定训练管线。

## 2. 代码结构现状
- 核心包：`src/memory_indexer/`
  - `pipeline.py`：端到端入口（建库 + 查询），含 coarse role 断言、缓存读写、检索委托。
  - `retriever.py`：候选集构建、精排打分、路由融合、指标输出（熵/覆盖/一致性/反事实等）。
  - `index.py`：粗召回索引 + 词法索引（支持 coarse / lexical / union 候选模式）。
  - `vectorizer.py`：向量组构造策略（当前主用 token_pool_topk）。
  - `encoder/`：基础编码接口 + simple/e5/hf sentence 编码器实现。
  - `scorer.py`：向量组打分器 + learned scorer（可加载 tiny reranker 权重）。
  - `ingest.py` / `models.py` / `store.py`：数据模型、入库、内存存储。
  - `trainer.py`：训练器占位，当前仅保留接口并返回基础报告。
- 脚本层：`scripts/`
  - `demo.py`：最小演示（默认 simple encoder，可切 learned scorer）。
  - `eval_router.py`：路由策略评测主脚本（Recall@k、MRR、top1、路由指标）。
  - `train_reranker.py` / `regression_learned_scorer.py`：轻量训练与回归验证。
- 数据层：`data/`
  - `Memory_Eval/`：easy/normal 两套 memory+eval 数据。
  - `VectorCache/`：query 与 memory 缓存（JSONL）。
  - `ModelWeights/`：`tiny_reranker.pt` 已存在，可直接用于 learned scorer。

## 3. 功能完成度
- 已完成：
  - 记忆库建库：文本 -> token 向量组 + coarse 向量 + 词法 token。
  - 缓存机制：按 encoder_id + strategy 过滤复用，降低重复编码成本。
  - 检索流程：coarse/lexical/union 候选 -> 向量组精排 -> 路由融合 -> Top-k 输出。
  - 路由策略：soft / half_hard / hard 三种 policy。
  - 路由监控：entropy、mass_at_k、consistency、counterfactual drop、candidate_size、coarse_lexical_jaccard。
  - 可解释输出：channel_weights、feature_keys、Top-ranked ids、候选模式说明。
- 部分完成：
  - learned scorer 已接入推理链路，但训练与评测规模仍偏小。
  - 多编码器组合（sentence + token）已支持，但默认 demo 仍以 simple encoder 为主。
- 未完成/待加强：
  - 真正可用的自监督训练器（当前 trainer 为占位实现）。
  - 系统级持久化索引（如 FAISS 真正落盘管理）与大规模性能压测。
  - 更稳定的中文语义编码默认方案（目前更偏工程骨架验证）。

## 4. 当前工程约束与已知风险
- 路由层风险：
  - soft 路由虽然可解释，但对“选错即失败”的约束仍弱。
  - hard 路由对召回质量更敏感，粗召回漏召回会直接放大错误。
- 数据风险：
  - 评测集规模仍小，容易高估策略效果。
  - easy/normal 集分布和真实线上数据存在差距。
- 表征风险：
  - simple encoder 便于回归，但语义上限低。
  - token 策略在中文场景仍受分词与停用词质量影响。

## 5. 可复现实验入口（给后续续写者）
- 建议先跑：
  1) `python scripts/demo.py`
  2) `python scripts/eval_router.py --dataset easy`
  3) `python scripts/eval_router.py --dataset normal --candidate-mode union`
- 若需验证 learned scorer：
  - 在上述命令加 `--use-learned-scorer --reranker-path data/ModelWeights/tiny_reranker.pt`。
- 观察重点：
  - 先看 Recall@k / MRR / top1，再看 entropy 与 mass_at_k 是否和策略预期一致。
  - 若 hard policy 指标异常，先排查 candidate_size 与 coarse_lexical_jaccard。

## 6. 下阶段优先级（执行建议）
- P0（优先马上做）
  - 固化一套“默认可复现评测命令 + 结果记录模板”（easy/normal 各一套）。
  - 补充小规模回归门槛（至少 top1、MRR、entropy 三指标阈值）。
- P1（短期）
  - 把 trainer 从占位升级为可训练小投影头，先接 in-batch negatives。
  - 扩展数据切分与缓存版本号，防止旧缓存污染新实验。
- P2（中期）
  - 加强 reranker 训练数据质量，做 hard negative 挖掘。
  - 增加“反事实删记忆”批量评估脚本，量化路由真实性。

## 7. 续写规范
- 仅在本文件末尾追加，不改历史条目。
- 每次追加必须包含：日期、变更摘要、关键函数名等等，其余自由发挥。
- 不必十分格式化，只需要政体简要、重要细节精准无误即可。

## 2026-02-15（learned scorer 分数饱和修复）

### 本次变更摘要
- 将 `LearnedFieldScorer.score()` 的推理主分从 `sigmoid(raw_score)` 改为 `raw_score`。
- debug 信息保留了三项：`raw_score`、`sigmoid_score`、`semantic_score`，方便对比。
- `scripts/eval_router.py` 的调试输出提升到 6 位小数，减少“显示上看不出差异”的假象。

### 经验教训
1. **不要把“训练常用激活”机械搬到“线上排序主分”**。
   - sigmoid 在高分区很容易饱和，分数看起来都差不多。
   - 一旦主分丢失差异，后面的路由和融合再精致也救不回来。

2. **先确认“信息有没有被你自己抹平”，再怀疑模型能力**。
   - 这次 raw 分其实有明显波动，但输出分被压平。
   - 排障顺序应该是：原始信号 -> 映射函数 -> 融合策略。
   - 下一步要做的是融合前的尺度校准（例如 z-score），不是回退修复。

### 后续行动建议
- 先在 easy / normal 数据集重跑对比，确认是否恢复“可分辨排序”。
- 增加一个简单守护检查：若 topN semantic 方差过低则报警。
- 规划 Router 融合前的通道标准化实验，避免某一路通道长期“独大”。

## 2026-02-15（多正例训练目标 + Bootstrap 评测 + 数量预测雏形）

### 本次变更摘要
- `scripts/train_reranker.py` 升级为兼容新旧数据格式：支持 `positives` 多正例字段，并对旧 `expected_mem_ids` 自动兼容。
- 训练新增 `--neg-strategy random|ranked`，可优先采样“排名靠前但非正例”的临界区负例。
- 训练新增 `--loss-type pairwise|listwise`：在 listwise 模式下直接优化“正例集合在候选集中的概率质量”。
- 增加 `CardinalityHead`（数量预测头）并支持 `--use-cardinality-head` 联合训练，保存到模型权重中。
- `Retriever` 增加 `use_khat` 推理开关（默认关闭），可在 learned scorer 可用时按预测 `k_hat` 截断结果。
- `scripts/eval_router.py` 增加 `--bootstrap`，输出 Recall@k / Top1 的置信区间，减少小幅波动误判。
- 新增 `scripts/data_collector.py` 与 `scripts/generate_training_samples.py`，打通交互日志到训练样本生成的最小闭环。

### 关键设计取舍
1. **默认行为不变**：新能力全部通过参数开关激活，旧命令可直接复用。
2. **最小侵入**：不改动现有 Router/policy 主流程，仅在训练目标与评测统计处加能力。
3. **可回滚**：listwise、ranked negatives、cardinality 均可单独关闭，便于逐步回归定位。

### 下一步建议
- 在安装 `torch` 的环境下对 pairwise/listwise 与 random/ranked 做系统对照，配合 bootstrap 报告判断显著性。
- 收集真实“补充追问”日志，批量生成 multi-positive 样本，逐步替代只含单正例的训练集。
- 在开启 `use_khat` 前，先以验证集统计 `k_hat` 的 MAE 分布，避免截断过度影响召回。

## 2026-02-17（ablation matrix 一键实验脚本）

### 本次变更摘要
- 新增 `scripts/run_ablation_matrix.py`，支持一条命令串行跑完 6 组配置 × 3 个 seed。
- 每个 `config + seed` 自动执行：训练（若需要）-> 评测（`eval_router.py` + bootstrap CI）-> 落盘日志与指标。
- 结果目录统一写入 `runs/<timestamp>/`，并生成 `summary.csv` 汇总关键指标。

### 如何运行
- 全量运行（默认 bootstrap=500，默认 seeds=11,29,47）：
  - `python scripts/run_ablation_matrix.py`
- 指定部分配置 / seeds（便于烟测）：
  - `python scripts/run_ablation_matrix.py --configs baseline --seeds 11 --bootstrap 20`

### 产物结构
- 总目录：`runs/<timestamp>/`
- 每组子目录：`runs/<timestamp>/<config_name>/seed_<seed>/`
  - `train.log.txt`：训练输出（baseline 组为说明文本）
  - `eval.log.txt`：评测输出原文
  - `eval.metrics.json`：解析后的关键指标
  - `weight_path.txt`：本次权重文件路径记录
  - `run.meta.json`：运行参数与文件索引
- 汇总表：`runs/<timestamp>/summary.csv`
  - 字段：`config_name, seed, Recall@5_mean, Recall@5_CI_low, Recall@5_CI_high, Top1_mean, MRR_mean`

### 配置说明
- 6 组配置分别为：
  - `baseline`
  - `pairwise_random`
  - `pairwise_ranked`
  - `listwise_random`
  - `listwise_ranked`
  - `listwise_ranked_cardinality`
- 其中 `listwise_ranked_cardinality` 仅在训练中开启 `use-cardinality-head`，评测不启用 `use_khat` 推理截断。

## 2026-02-18（run-dir/cache/config 统一规范）

### 本次变更摘要
- `scripts/eval_router.py` 新增 `--run-dir` 与 `--config`：
  - 传 `--run-dir` 时，写出 `eval.log.txt`、`eval.metrics.json`、`config.snapshot.json`
  - 默认配置可从 `configs/default.yaml` 读取，CLI 参数可覆盖
- `scripts/train_reranker.py` 新增 `--run-dir` 与 `--config`：
  - 传 `--run-dir` 时，写出 `train.log.txt`、`train.metrics.json`、`config.snapshot.json`
  - 训练权重优先写到 `run-dir/tiny_reranker.pt`，并兼容复制到 `--save-path`
- `scripts/run_ablation_matrix.py` 改为配置驱动：
  - 支持 `--config`、`--encoder-backend`，并透传到训练+评测
  - 每个 seed 结果写在 `runs/<timestamp>/<config>/seed_<seed>/`
  - 训练权重双落盘：`runs/.../tiny_reranker.pt` + `data/ModelWeights/<config>__seed_<seed>.pt`

### 缓存规范（核心）
- cache 文件改为签名隔离命名（dataset/backend/encoder/strategy/k/version）
- memory cache 与 eval cache 都写入签名头（第一行 `_meta.cache_signature`）
- 读取时签名不匹配会自动重建，避免跨配置误复用导致“能跑但不可信”

### 唯一推荐入口（批量实验）
- `python scripts/run_ablation_matrix.py`
- 如需强制后端：
  - `python scripts/run_ablation_matrix.py --encoder-backend hf`
  - `python scripts/run_ablation_matrix.py --encoder-backend simple`

### 兼容原则
- 未传 `--run-dir` 时，保持旧行为（可继续使用旧路径）
- 未传 `--config` 时，默认读取 `configs/default.yaml`

## 2026-02-19（run registry + cache 指纹 + 轻量模型管理）
### 本次变更摘要
- 新增全局实验索引：`runs/registry.csv`。
- `scripts/eval_router.py`、`scripts/train_reranker.py`、`scripts/run_ablation_matrix.py` 在写入 run-dir 后会幂等 upsert 到 registry（按 `run_dir` 去重更新）。
- 新增 `scripts/list_runs.py`：按 dataset/backend/loss_type 等筛选最近 runs。
- 新增 `scripts/select_best_run.py`：按指标（默认 `Recall@5`）选最优 run，并落到 `runs/best/<dataset>/<encoder_backend>/`。
- 新增 `scripts/clean_cache.py`：按 dataset/backend/签名片段选择性清理 `data/VectorCache`。
- cache 签名增强：在 dataset/backend/encoder/strategy/k 基础上加入数据指纹（memory/eval 文件 sha1 short），并提升为 `cache_v=v2`，避免“文件内容变了但路径没变”的错复用。
- 训练权重写入策略调整：
  - 传 `--run-dir` 时默认只写 `run-dir/tiny_reranker.pt`。
  - 不再默认覆盖 `data/ModelWeights/tiny_reranker.pt`。
  - 仅在显式传 `--save-path` 或 `--export-weights-to` 时额外导出。
- README 追加了推荐入口：`list_runs` / `select_best_run` / `clean_cache` / best 权重复现 eval 命令。

### 本次新增/修改文件
- 新增：`scripts/list_runs.py`
- 新增：`scripts/select_best_run.py`
- 新增：`scripts/clean_cache.py`
- 增强：`scripts/runtime_utils.py`（registry upsert、git commit、data fingerprint）
- 修改：`scripts/eval_router.py`
- 修改：`scripts/train_reranker.py`
- 修改：`scripts/run_ablation_matrix.py`
- 追加：`README.md`
- 分析：`analysis/system_readiness_2026-02-18.md`

### 烟测记录（本地终端）
- 语法检查：

## 2026-02-20（数据管道纲领对齐：用户语料优先）

### 本次对齐摘要
- 明确了数据处理总纲（先对齐原则，再做实现细节）：
  1) 优先提取用户发言；
  2) 先规则清洗明显复制粘贴大段内容（代码块仅为例，不限于代码）；
  3) 必须保持会话内顺序；
  4) 先按对话窗口分段，再用句向量相似度做话题断裂补充；
  5) 同一事件归为 cluster，cluster 内互为候选正例；
  6) 先规则法打底，再决定是否引入 LLM 摘要。

### 结构化建议（已写入 README）
- 中间产物建议固定为：
  - `data/Processed/user_turns_raw.jsonl`
  - `data/Processed/user_turns_dedup.jsonl`
- 最小字段：
  - `session_id/turn_id/role/text/timestamp`
  - `user_message_clean/topic_break_flag/cluster_id/candidate_pool_ids`

### 关键实现约束
- 顺序不可破坏：任何清洗/聚类都不能改写原 turn 时序。
- 话题断裂先用启发式阈值（建议起点：相邻 user turn 相似度 < 0.35 且新关键词明显），后续再调参。
- 训练向约束：任一 cluster 内样本均可单独作为 query；后续必须加入 query 多表达增强，避免单一表述过拟合。

## 2026-02-21（新增聊天记忆处理器并列包）

### 本次变更摘要
- 新增并列包：`src/chat_memory_processor/`
  - `extractor.py`：从 DeepSeek 风格导出中提取用户发言
  - `cleaning.py`：规则清洗与大段复制粘贴检测
  - `segmentation.py`：相邻 turn 相似度 + 新词比例做话题断裂候选
  - `pipeline.py`：保序、聚集、双文件输出
  - `models.py`：用户 turn 数据结构
- 新增脚本：`scripts/chat_memory/build_user_turns.py`
  - 默认读取 `data/RawDeepseekChats/conversations_sample.json`
  - 默认输出
    - `data/Processed/user_turns_raw.jsonl`
    - `data/Processed/user_turns_dedup.jsonl`

### 为什么并列而不是塞进 memory_indexer
- `memory_indexer` 关注检索/路由/打分；
- `chat_memory_processor` 关注原始聊天语料处理；
- 两者并列后，边界清晰、依赖方向单一，后续替换任一模块都更稳。

## 2026-02-21（切回 conversations.json 主路径）

### 本次调整
- 明确将 `data/RawDeepseekChats/conversations.json` 作为正式输入源（标准 JSON）。
- 删除/回退仅针对 sample 截段格式的非常规解析分支，避免长期维护无效兼容逻辑。
- `build_user_turns.py` 默认输入改为 `conversations.json`。
- 抽取逻辑改为“按 conversation 处理 + 会话内保序 + 会话内聚集”，不跨会话混切。

## 2026-02-21（讨论留痕：自动切分 + 聚类 + 低成本 query 反推）

### 本次共识
- 继续坚持：同一事件 cluster 内互为候选正例，服务 listwise 排序。
- 话题切分不建议长期依赖固定阈值；应优先“会话内自适应阈值/变化点检测”。
- query 扩展不强依赖 LLM：先做模板+词法+同义替换的低成本反推方案。
- 跨会话聚合不禁用，但建议后置为二阶段增强能力。

### 文档产物
- 新增：`README/话题切分与聚类方案.md`
  - 给出默认执行路径、接口预留、与 listwise 的衔接方式。
  - `python -m py_compile scripts/runtime_utils.py scripts/train_reranker.py scripts/eval_router.py scripts/run_ablation_matrix.py scripts/list_runs.py scripts/select_best_run.py scripts/clean_cache.py`
- 最小训练（simple/followup）：成功写入 `runs/tmp_registry_train/tiny_reranker.pt`。
- 最小评测（simple/followup）：成功产出 `runs/tmp_registry_eval/eval.metrics.json`。
- ablation 最小对照（pairwise_ranked, seed=11）：成功生成 `runs/<timestamp>/summary.csv`。
- registry 幂等验证：同一 `run_dir` 重跑不会重复新增行。
- best 选择验证：`select_best_run` 可生成 `runs/best/followup/simple/`。

### 备注
- 目前项目里仍有历史 `v1` cache 文件；建议先用 `clean_cache --dry-run` 查看再定向清理。
- 后续新增/修改脚本时，开发日志会同步追加更新。

## 2026-02-19（编码器前缀修复 + runtime 固化入口）
### 本次变更摘要
- 修复 `HFSentenceEncoder` 的 E5 前缀开关：
  - `src/memory_indexer/encoder/hf_sentence.py` 的 `_maybe_prefix()` 现在尊重 `self.use_e5_prefix`，并仅在 `model_name` 包含 `e5` 时添加 `query:/passage:` 前缀。
  - 保持 `_resolve_local_files_only()` 逻辑不变（默认离线策略未改）。
- 为 `E5TokenEncoder` 增加软护栏，避免双前缀：
  - `src/memory_indexer/encoder/e5_token.py` 的 `encode_tokens()` 现在会先检查输入是否已以 `query:` 或 `passage:` 开头；若已带角色前缀则不再二次 `_maybe_prefix()`。
  - 避免未来 `use_e5_prefix=True` 场景出现 `query: passage: ...` 的角色错乱。
- 占位 token vec 风险处理：
  - 已排查主链路（`eval_router/train_reranker/generate_training_samples` 的 hf 路径）均显式传 `token_encoder=E5TokenEncoder`。
  - 在 `HFSentenceEncoder.encode_tokens()` 中加入 trace 模式一次性 warn（`MEMORY_TRACE=1` 时），提醒该方法返回的是占位 token vec，正式实验应使用 E5TokenEncoder。
- 新增 runtime 可执行入口（替代手动 IDE 运行配置）：
  - `scripts/runtime/make_followup_eval.py`
  - `scripts/runtime/eval_hf_normal.py`
  - `scripts/runtime/ablate_followup_listwise_vs_pairwise.py`
  - `scripts/runtime/select_best_followup_hf.py`
  - 每个脚本启动时都会打印提醒：可用 `list_runs/select_best_run` 查看与挑选最佳实验。
  - runtime 脚本会优先使用项目 `.venv/Scripts/python.exe`（若存在），否则回退 `sys.executable`。
- `run_ablation_matrix` 增强：
  - 新增 `--run-dir`，允许固定输出到精确目录（不再强制追加 timestamp）。
- 修复一个运行期兼容问题：
  - `scripts/runtime_utils.py` 的 `Tee` 新增 `isatty()`，避免 `transformers` 在日志输出阶段触发 AttributeError。

### 最小验证（B：eval_hf_normal）
- 实际执行：`python scripts/runtime/eval_hf_normal.py`
- 结果：已成功启动 HF/E5 链路并进入评测，日志中出现关键指标：
  - `Recall@k=0.780`
  - `coarse_lexical_jaccard=0.146`
- 结论：无“世界观突变”迹象（指标量级与既有预期一致）。
- 备注：完整全量评测在当前终端会超过单次命令超时窗口，但启动与核心指标已确认正常。

## 2026-02-19（快速止血：runtime 参数固化 + 训练默认修正 + 防覆盖备份）
### 本次变更摘要
- `scripts/runtime/eval_hf_normal.py` 已按常用命令固定关键参数，不再依赖 default.yaml 的隐式默认：
  - `--hf-local-only`
  - `--top-n 30 --top-k 5`
  - `--policies half_hard,soft`
  - `--candidate-mode union`
  - `--ablation-groups baseline(auto),S-only,L-only`
  - `--use-learned-scorer --reranker-path data/ModelWeights/tiny_reranker.pt`
  - `--no-consistency-pass`
- `configs/default.yaml` 训练默认值调整：`train_reranker.epochs` 从 3 改为 10。
- `scripts/train_reranker.py` 新增轻量防覆盖保险丝：
  - 当目标写入路径为 `data/ModelWeights/tiny_reranker.pt` 且该文件已存在时，先自动备份为
    `data/ModelWeights/tiny_reranker.bak_YYYYmmdd_HHMMSS.pt`，再覆盖写入。

### 影响
- 运行 `python scripts/runtime/eval_hf_normal.py` 会直接产出你熟悉的评测视图（组别/策略/检索配置固定）。
- 误训练覆盖风险降低：即便直接写默认权重，也会先留一份时间戳备份。

## 2026-02-19（A-E 一次性改造：listwise/pairwise 正式对照主线）
### A) 生成规则去 user_feedback 硬依赖
- `scripts/generate_training_samples.py` 已移除 followup 对 user_feedback 关键词的硬门槛。
- 新默认：`turn_index > 0` 且 `curr_turn.cited_mem_ids` 非空就产样本。
- `positives`：优先 `prev_cites ∩ curr_cites`，若空则用 `curr_cites`。
- `hard_negatives`：`prev_cites - positives`（可空）。

### B) 增加“从 eval 合成 followup”通路
- `scripts/generate_training_samples.py` 新增 `--from-eval-dataset <name>`。
- 可直接从 `eval_normal.jsonl` 合成 followup 样本，再补全 candidates/hard_negatives，输出到 `data/Processed/eval_followup.jsonl`。
- `scripts/runtime/make_followup_eval.py` 同步支持：
  - `--from-eval-dataset normal`（不依赖真实日志）
  - 或 `--log-path ...`（真实日志）

### C) 训练入口拆分 + 权重正规化
- 新增 `scripts/train_pairwise_reranker.py`：固定 `loss_type=pairwise`、`neg_strategy=ranked`，默认写 `data/ModelWeights/pairwise_reranker.pt`。
- 新增 `scripts/train_listwise_reranker.py`：固定 `loss_type=listwise`、`neg_strategy=ranked`，默认写 `data/ModelWeights/listwise_reranker.pt`。
- 两个 wrapper 在覆盖前都会自动备份 `.bak_时间戳`。

### D) 显式对比 runtime 脚本
- 新增 `scripts/runtime/compare_followup_pairwise_vs_listwise.py`：
  1) 调 `train_pairwise_reranker`
  2) 调 `train_listwise_reranker`
  3) 分别调用 `eval_router --use-learned-scorer --reranker-path ...`
  4) 终端打印 Recall@5/Top1/MRR 对比表

### E) eval_router 增加权重与 meta 可见性
- `scripts/eval_router.py` 在 `--use-learned-scorer` 时会打印：
  - 当前加载的权重路径
  - 权重内 `meta`（loss_type/neg_strategy/epochs/seed/dataset，若存在）

### 实测
- 已用 `simple` 路径执行完整对照：
  - `python scripts/runtime/compare_followup_pairwise_vs_listwise.py --encoder-backend simple --epochs 1 --top-n 20 --top-k 5 --bootstrap 5 --seed 11`
- 成功输出对比表与产物目录：
  - `runs/rt/compare_followup_pairwise_vs_listwise/<timestamp>/...`

### 正式执行（HF/E5）推荐顺序
1) 先合成/重建 followup 数据（不依赖日志）：
   - `python scripts/runtime/make_followup_eval.py --from-eval-dataset normal --encoder-backend hf --top-n 30 --candidate-mode union`
2) 再跑显式对照：
   - `python scripts/runtime/compare_followup_pairwise_vs_listwise.py --encoder-backend hf --epochs 10 --top-n 30 --top-k 5 --bootstrap 200 --seed 11`

## 2026-02-19（compare 默认减负 + 训练设备默认 GPU）
### 本次变更摘要
- `scripts/runtime/compare_followup_pairwise_vs_listwise.py`：
  - 默认 `--bootstrap=0`（不做 bootstrap 重采样）。
  - 默认不训练；新增 `--train` 才会触发 pairwise/listwise 训练。
  - 默认不训练时会检查权重文件是否存在，不存在直接报清晰错误。
  - 新增 `--device`（仅 `--train` 时生效），用于显式传训练设备。
  - 代码内加入注释，说明为何默认关闭 bootstrap、为何默认跳过训练（这是踩坑位）。
- `scripts/train_reranker.py`：
  - 训练默认设备从配置读取时默认值改为 `cuda`。
  - 增加设备自动降级逻辑：
    - `device=auto/gpu/cuda` 时：有 GPU 用 CUDA，无 GPU 自动回退 CPU。
    - 显式请求 `cuda*` 但机器无 GPU 时会打印 warn 并回退 CPU。
  - 代码内加入注释，说明这个策略是为避免“默认 CPU 巨慢”坑。
- `configs/default.yaml`：
  - `train_reranker.device` 从 `cpu` 改为 `cuda`。

### 影响
- 对比脚本现在默认更接近“只评估，不重复训练”的使用习惯。
- 训练默认倾向 GPU，降低误用 CPU 导致的超慢问题。

## 2026-02-20（新增一键训练：pairwise + listwise）
### 新增脚本
- `scripts/runtime/train_pairwise_and_listwise_reranker.py`

### 设计目标
- 避免每次手敲一长串参数。
- 一次命令顺序训练：
  1) `scripts.train_pairwise_reranker`
  2) `scripts.train_listwise_reranker`
- 统一产物目录：`runs/rt/train_pairwise_and_listwise/<timestamp>/...`
- 固定权重路径（便于后续 eval/compare）：
  - `data/ModelWeights/pairwise_reranker.pt`
  - `data/ModelWeights/listwise_reranker.pt`

### 关键参数与坑位处理
- `--profile formal|quick`：
  - `formal` 默认 `epochs=20, top_n=30`
  - `quick` 默认 `epochs=3, top_n=20`
- `--device` 默认 `cuda`（底层 train_reranker 已支持无 GPU 自动降级到 CPU）
- `--reset-weights`：训练前删除这两个正式权重（不删 `.bak`）
- 默认 `hf-local-only`（除非显式 `--hf-online`）

### 推荐使用
- 正式训练（HF/E5）：
  - `python scripts/runtime/train_pairwise_and_listwise_reranker.py --encoder-backend hf --profile formal --seed 11 --reset-weights`
- 快速冒烟：
  - `python scripts/runtime/train_pairwise_and_listwise_reranker.py --encoder-backend simple --profile quick --epochs 1 --top-n 20 --seed 11 --reset-weights`

## 2026-02-20（compare 报错修复 + 日志降噪）
### 修复
- `scripts/runtime/compare_followup_pairwise_vs_listwise.py`：
  - run-dir 全部改为绝对路径（基于 `REPO_ROOT`），避免在不同工作目录下解析失败导致
    `FileNotFoundError: .../eval.metrics.json`。
  - 在读取评测结果前新增存在性检查，缺失时给出明确提示并指向对应 `eval.log.txt`。

### 日志降噪
- compare 子进程默认注入环境变量：
  - `TQDM_DISABLE=1`
  - `HF_HUB_DISABLE_PROGRESS_BARS=1`
- 目的：减少 `Loading weights ...` 这类第三方进度条噪音。

### 结论核验
- pairwise/listwise 权重文件不是同一个：
  - `pairwise_reranker.pt` 与 `listwise_reranker.pt` 的 SHA1 前缀不同。
- 但当前一次实测指标完全一致，属于“不同模型在当前数据/候选分布上学到近似排序边界”的结果，并非路径误用。
