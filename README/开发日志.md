【维护规则】本日志仅允许“追加补充”，禁止删除或改写既有内容。


# 开发日志（项目现状快照）
更新时间：2026-02-15

## 1. 项目定位与当前阶段
- 项目名称：Memory Indexer（记忆唤醒索引器）。
- 当前主目标：把输入文本转成“可检索指令”，通过粗召回 + 精排 + 路由输出 Top-k 记忆。
- 阶段判断：
  - MVP 检索闭环已成型（可建库、可检索、可评估、可演示）。
  - 软/半硬/硬路由接口已落地，可观测指标已接入。
  - 自监督训练仍是“骨架接口 + 小规模实验脚本”阶段，未形成稳定训练管线。

## 2. 代码结构现状
- 核心包：`src/memory_indexer/`
  - `pipeline.py`：端到端入口（建库 + 查询），含 coarse role 断言、缓存读写、检索委托。
  - `retriever.py`：候选集构建、精排打分、路由融合、指标输出（熵/覆盖/一致性/反事实等）。
  - `index.py`：粗召回索引 + 词法索引（支持 coarse / lexical / union 候选模式）。
  - `vectorizer.py`：向量组构造策略（当前主用 token_pool_topk）。
  - `encoder/`：基础编码接口 + simple/e5/hf sentence 编码器实现。
  - `scorer.py`：向量组打分器 + learned scorer（可加载 tiny reranker 权重）。
  - `ingest.py` / `models.py` / `store.py`：数据模型、入库、内存存储。
  - `trainer.py`：训练器占位，当前仅保留接口并返回基础报告。
- 脚本层：`scripts/`
  - `demo.py`：最小演示（默认 simple encoder，可切 learned scorer）。
  - `eval_router.py`：路由策略评测主脚本（Recall@k、MRR、top1、路由指标）。
  - `train_reranker.py` / `regression_learned_scorer.py`：轻量训练与回归验证。
- 数据层：`data/`
  - `Memory_Eval/`：easy/normal 两套 memory+eval 数据。
  - `VectorCache/`：query 与 memory 缓存（JSONL）。
  - `ModelWeights/`：`tiny_reranker.pt` 已存在，可直接用于 learned scorer。

## 3. 功能完成度
- 已完成：
  - 记忆库建库：文本 -> token 向量组 + coarse 向量 + 词法 token。
  - 缓存机制：按 encoder_id + strategy 过滤复用，降低重复编码成本。
  - 检索流程：coarse/lexical/union 候选 -> 向量组精排 -> 路由融合 -> Top-k 输出。
  - 路由策略：soft / half_hard / hard 三种 policy。
  - 路由监控：entropy、mass_at_k、consistency、counterfactual drop、candidate_size、coarse_lexical_jaccard。
  - 可解释输出：channel_weights、feature_keys、Top-ranked ids、候选模式说明。
- 部分完成：
  - learned scorer 已接入推理链路，但训练与评测规模仍偏小。
  - 多编码器组合（sentence + token）已支持，但默认 demo 仍以 simple encoder 为主。
- 未完成/待加强：
  - 真正可用的自监督训练器（当前 trainer 为占位实现）。
  - 系统级持久化索引（如 FAISS 真正落盘管理）与大规模性能压测。
  - 更稳定的中文语义编码默认方案（目前更偏工程骨架验证）。

## 4. 当前工程约束与已知风险
- 路由层风险：
  - soft 路由虽然可解释，但对“选错即失败”的约束仍弱。
  - hard 路由对召回质量更敏感，粗召回漏召回会直接放大错误。
- 数据风险：
  - 评测集规模仍小，容易高估策略效果。
  - easy/normal 集分布和真实线上数据存在差距。
- 表征风险：
  - simple encoder 便于回归，但语义上限低。
  - token 策略在中文场景仍受分词与停用词质量影响。

## 5. 可复现实验入口（给后续续写者）
- 建议先跑：
  1) `python scripts/demo.py`
  2) `python scripts/eval_router.py --dataset easy`
  3) `python scripts/eval_router.py --dataset normal --candidate-mode union`
- 若需验证 learned scorer：
  - 在上述命令加 `--use-learned-scorer --reranker-path data/ModelWeights/tiny_reranker.pt`。
- 观察重点：
  - 先看 Recall@k / MRR / top1，再看 entropy 与 mass_at_k 是否和策略预期一致。
  - 若 hard policy 指标异常，先排查 candidate_size 与 coarse_lexical_jaccard。

## 6. 下阶段优先级（执行建议）
- P0（优先马上做）
  - 固化一套“默认可复现评测命令 + 结果记录模板”（easy/normal 各一套）。
  - 补充小规模回归门槛（至少 top1、MRR、entropy 三指标阈值）。
- P1（短期）
  - 把 trainer 从占位升级为可训练小投影头，先接 in-batch negatives。
  - 扩展数据切分与缓存版本号，防止旧缓存污染新实验。
- P2（中期）
  - 加强 reranker 训练数据质量，做 hard negative 挖掘。
  - 增加“反事实删记忆”批量评估脚本，量化路由真实性。

## 7. 续写规范
- 仅在本文件末尾追加，不改历史条目。
- 每次追加必须包含：日期、变更摘要、关键函数名等等，其余自由发挥。
- 不必十分格式化，只需要政体简要、重要细节精准无误即可。

## 2026-02-15（learned scorer 分数饱和修复）

### 本次变更摘要
- 将 `LearnedFieldScorer.score()` 的推理主分从 `sigmoid(raw_score)` 改为 `raw_score`。
- debug 信息保留了三项：`raw_score`、`sigmoid_score`、`semantic_score`，方便对比。
- `scripts/eval_router.py` 的调试输出提升到 6 位小数，减少“显示上看不出差异”的假象。

### 经验教训
1. **不要把“训练常用激活”机械搬到“线上排序主分”**。
   - sigmoid 在高分区很容易饱和，分数看起来都差不多。
   - 一旦主分丢失差异，后面的路由和融合再精致也救不回来。

2. **先确认“信息有没有被你自己抹平”，再怀疑模型能力**。
   - 这次 raw 分其实有明显波动，但输出分被压平。
   - 排障顺序应该是：原始信号 -> 映射函数 -> 融合策略。
   - 下一步要做的是融合前的尺度校准（例如 z-score），不是回退修复。

### 后续行动建议
- 先在 easy / normal 数据集重跑对比，确认是否恢复“可分辨排序”。
- 增加一个简单守护检查：若 topN semantic 方差过低则报警。
- 规划 Router 融合前的通道标准化实验，避免某一路通道长期“独大”。
